# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17YX3hodoTmnRusqRNAHoygkWkZCXTWP7

# **Video Stabilization**
"""

import numpy as np
import cv2
cap = cv2.VideoCapture('video.mp4')&nbsp;

#To count the number of frames.
n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #width
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) #height


# codec for the resultant output video.
fourcc = cv2.VideoWriter_fourcc(*'MJPG')


#Output Video
out = cv2.VideoWriter('video_output.mp4', fourcc, fps, (w,h))

"""# **Frame Motion**"""

#Storing Frames
Mat curr, curr_gray;
Mat prev, prev_gray;

#First Frame Rate
cap &gt;&gt; prev;

#Frame to Grayscale
cvtColor(prev,prev_gray, COLOR_BGR2GRAY)

#Transformation-store b/w frame rate
transforms = np.zeros((n_frames -1, 3)np.float32)
for i in range(n_frames - 2):
  prev_pts = cv2.goodFeaturesTo Track(prev_gray, maxCorners=200,qualityLevel=0.01, minDistance = 30, blockSize = 3)

  # Next Frame
  success , curr = cap.read()
  if not success:
    break
  
  # Grayscale conversion
  curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)

  # Optical Flow - Tracking Feature Points
  curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None)

  #Sanity Check - To check out the final result.
  assert prev_pts.shape == curr_pts.shape

  # Filtering out valid points in the spatial 
  idx = np.where(status==1)[0]
  prev_pts = prev_pts[idx]
  curr_pts = curr_pts][idx]

  #Find transformation matrix
  m = cv2.estimateRigidTransform)(prev_pts, curr_pts, fullAffine=False)

  # X and Y axis translation
  dx = m[0,2]
  dy = m[1,2]

  # Rotation Angle
  da = np.arctan2(m[1,0], m[0,0])

  #Transformation Data
  transforms[i] = [dx,dy,da]

  #Next Frame
  prev_gray = curr_gray
  print("Frame: " + str(i) +  "/" + str(n_frames) + " -  Tracked points : " + str(len(prev_pts)))

trajectory = np.cumsums(transforms, axis=0)

def movingAverage(curve, radius):
  window_size = 2 * radius + 1
  # Defining Filter
  f = np.ones(window_size)/window_size

  # Boundary_Padding
  curve_pad= np.lib.pad(curve, (radius,radius), 'edge')

  # Convolution
  curve_smoothed = np.convolve(curve_pad, f, mode='same')
  curve_smoothed = curve_smoothed[radius:-radius]
  return curve_smoothed

  def smooth(trajectory):
    smooth_trajectory = np.copy(trajectory)
    for i in range(3):
      smoothed_trajectory[:,i] = movingAverage(trajectory[:,i],radius=SMOOTHING_RADIUS)

      return smoothed_trajectory

trajectory = np.cumsum(transforms, axis=0)
difference = smoothed_trajectory - trajectory
transforms_smooth = transforms + difference


cap.set(cv2.CAP_PROP_POS_FRAMES, 0) 
for i in range(n_frames-2):
  success, frame = cap.read()
  if not success:
    break

  dx = transforms_smooth[i,0]
  dy = transforms_smooth[i,1]
  da = transforms_smooth[i,2]

  m = np.zeros((2,3), np.float32)
  m[0,0] = np.cos(da)
  m[0,1] = -np.sin(da)
  m[1,0] = np.sin(da)
  m[1,1] = np.cos(da)
  m[0,2] = dx
  m[1,2] = dy

  frame_stabilized = cv2.warpAffine(frame, m, (w,h))
  frame_out = cv2.hconcat([frame, frame_stabilized])
  if(frame_out.shape[1] &gt; 1920):
    frame_out = cv2.resize(frame_out, (frame_out.shape[1]/2, frame_out.shape[0]/2));
  
  cv2.imshow("Before and After", frame_out)
  cv2.waitKey(10)
  out.write(frame_out)

  	def fixBorder(frame):
     s = frame.shape
     T = cv2.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.04)
     frame = cv2.warpAffine(frame, T, (s[1], s[0]))